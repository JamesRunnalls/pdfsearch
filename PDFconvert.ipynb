{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load packages and define functions\n",
    "\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfpage import PDFTextExtractionNotAllowed\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "import pdfminer\n",
    "import re\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os\n",
    "import numpy\n",
    "import glob\n",
    "\n",
    "# Function for removing unwanted clutter from the pdf outputs. \n",
    "def clean(x):\n",
    "    # Set up regex for removing non-alphabet characters\n",
    "    regex = re.compile('[+=,\\.!?0-9]')\n",
    "    xn = []\n",
    "    for y in x:\n",
    "        # Shorten any stings of the same letter to two letter e.g. Whooooosh to Whoosh\n",
    "        y = re.sub(r'(.)\\1{2,}', r'', y, flags=re.DOTALL)\n",
    "        try:\n",
    "            # This checks that the longest word in the string is longer than 2 characters and that there is more than one word. \n",
    "            if len(max(regex.sub('',y).split(), key=len)) > 2 and len(y.split()) > 2:\n",
    "                # This allows you to replace the degree and diameter symbols with text\n",
    "                y = y.encode('utf-8')\n",
    "                y = y.replace(\"-\",\" \").replace(\"\\xc2\\xb0\",\" DEGREE\").replace(\"\\xc3\\x98\",\" DIAMETER\")\n",
    "                xn.append(y)\n",
    "        except:\n",
    "            pass\n",
    "    return xn\n",
    "\n",
    "# Function for extracting the pdf textboxes as list of strings\n",
    "def parse_obj(lt_objs):\n",
    "    x = []\n",
    "    # loop over the object list\n",
    "    for obj in lt_objs:\n",
    "\n",
    "        # if it's a textbox, print text and location\n",
    "        if isinstance(obj, pdfminer.layout.LTTextBoxHorizontal):\n",
    "             x.append(obj.get_text().replace('\\n', ' '))\n",
    "\n",
    "        # if it's a container, recurse\n",
    "        elif isinstance(obj, pdfminer.layout.LTFigure):\n",
    "            parse_obj(obj._objs)\n",
    "    return x\n",
    "\n",
    "# Function for extracting a list of strings from a pdf\n",
    "def convert(fname):\n",
    "\n",
    "    # Open a PDF file.\n",
    "    fp = open(fname, 'rb')\n",
    "\n",
    "    # Create a PDF parser object associated with the file object.\n",
    "    parser = PDFParser(fp)\n",
    "\n",
    "    # Create a PDF document object that stores the document structure.\n",
    "    # Password for initialization as 2nd parameter\n",
    "    document = PDFDocument(parser)\n",
    "\n",
    "    # Check if the document allows text extraction. If not, abort.\n",
    "    if not document.is_extractable:\n",
    "        raise PDFTextExtractionNotAllowed\n",
    "\n",
    "    # Create a PDF resource manager object that stores shared resources.\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "\n",
    "    # Create a PDF device object.\n",
    "    device = PDFDevice(rsrcmgr)\n",
    "\n",
    "    # BEGIN LAYOUT ANALYSIS\n",
    "    # Set parameters for analysis.\n",
    "    # Other parameters you can use: char_margin=0.01, word_margin=0.2, line_margin=0.3\n",
    "    laparams = LAParams(all_texts=True, detect_vertical=False)\n",
    "\n",
    "    # Create a PDF page aggregator object.\n",
    "    device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    \n",
    "    # loop over all pages in the document\n",
    "    for page in PDFPage.create_pages(document):\n",
    "\n",
    "        # read the page into a layout object\n",
    "        interpreter.process_page(page)\n",
    "        layout = device.get_result()\n",
    "\n",
    "        # extract text from this object\n",
    "        x = parse_obj(layout._objs)\n",
    "    \n",
    "    # Clean output data\n",
    "    xn = clean(x)\n",
    "    \n",
    "    return xn\n",
    "\n",
    "# Fucntion for extracting all the drawings and date produced from a given job area\n",
    "def drawlist(Area):\n",
    "    DL = []\n",
    "    DT = []\n",
    "    Jobs = \"\\\\\\\\global\\\\europe\\\\Cardiff\\\\Jobs\\\\\"\n",
    "    Strut = \"\\\\4 Internal Project Data\\\\4-30 Drawings\\\\4-31 Issue Drawings\\\\Plots\"\n",
    "    \n",
    "    # Find all the job folders in job area\n",
    "    root, dirs, files = os.walk(Jobs+Area).next()\n",
    "    \n",
    "    # Find all the pdfs in the issue drawings plot area for each job number\n",
    "    for x in dirs:\n",
    "        try:\n",
    "            os.chdir(Jobs+Area+\"\\\\\"+x+Strut)\n",
    "            for file in glob.glob(\"*.pdf\"):\n",
    "                DL.append(Jobs+Area+\"\\\\\"+x+Strut+\"\\\\\"+file)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #Find the date each pdf was produced\n",
    "    for c in DL:\n",
    "        DT.append(os.path.getctime(c))\n",
    "    \n",
    "    # Transform lists into a datframe\n",
    "    di = dict(zip(DL, DT))\n",
    "    df = pd.DataFrame(di.items(), columns=[\"Filename\",\"Date Created\"])\n",
    "    df['Date Created'] = pd.to_datetime(df['Date Created'],unit='s')\n",
    "    df['Date Created'] = df['Date Created'].dt.date\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe of textbox values and write to csv\n",
    "df = drawlist('241000')\n",
    "dk = pd.read_csv('C:\\\\Users\\\\james.runnalls\\\\Documents\\\\Jupyter\\\\Output.csv', names=['FID', 'Text', 'Filename', 'Date Created'])\n",
    "dk = dk.drop('FID', axis=1).drop('Text', axis=1).drop_duplicates()\n",
    "dk['Date Created'] = pd.to_datetime(dk['Date Created'])\n",
    "dk['Date Created'] = dk['Date Created'].dt.date\n",
    "merge = df.merge(dk, how='left', indicator=True)\n",
    "df = merge[merge['_merge']=='left_only']\n",
    "#df = df.head(50)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        xn = convert(row['Filename'])\n",
    "        xd = [row['Filename']]*len(xn)\n",
    "        xx = dict(zip(xn,xd))\n",
    "        dn = pd.DataFrame(xx.items(), columns=[\"Text\",\"Filename\"])\n",
    "        dn['Date Created'] = row['Date Created']\n",
    "        with open('C:\\\\Users\\\\james.runnalls\\\\Documents\\\\Jupyter\\\\Output.csv', 'ab') as f:\n",
    "            dn.to_csv(f, header=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Clear the csv for starting again\n",
    "#f = open('C:\\\\Users\\\\james.runnalls\\\\Documents\\\\Jupyter\\\\Output.csv', \"w+\")\n",
    "#f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
